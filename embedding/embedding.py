import numpy as np
import math
import torch
import torch.nn as nn

def create_embedding_layer(vocab_size: int, d_model: int) -> nn.Embedding:
    """
    Create an embedding layer
    """
    embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=d_model) 
    return embedding

def embed_tokens(embedding: nn.Embedding, tokens: torch.Tensor, d_model: int) -> torch.Tensor:
    """
    Convert token indices to scaled embeddings.
    """
    return embedding(tokens) * math.sqrt( d_model  )